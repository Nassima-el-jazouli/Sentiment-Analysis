{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- L'importation des données :\n",
    "\n",
    "Dans un premier temps on importe les bibliothèques dont on aura besoin :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "#imports\n",
    "import string # from some string manipulation tasks\n",
    "import nltk # natural language toolkit\n",
    "import re # regex\n",
    "from string import punctuation # solving punctuation problems\n",
    "from nltk.corpus import stopwords # stop words in sentences\n",
    "from nltk.stem import WordNetLemmatizer # For stemming the sentence\n",
    "from nltk.stem import SnowballStemmer # For stemming the sentence\n",
    "\n",
    "#from contractions import contractions_dict # to solve contractions\n",
    "#from autocorrect import Speller #correcting the spellings\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pylab as pl \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Import sklearn \n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "import seaborn as sns  # Bibliothèque pour la visualisation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise la bibliothèque pandas pour récupérer les données à partir d'un fichier text qu'on le met soit dans le meme dossier que notre notebook ou on initialise la fonction read_table() par le chemin dont on a notre fichier.\n",
    "names : c'est pour préciser les colonnes qu'on veut : Ici on divise la data en deux colonnes : la première contient les commentaires et la deuxième contient les sentiments exprimés en 1 ou 0. Ces deux colonnes sont délimités par la touche tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>I just got bored watching Jessice Lange take h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>Unfortunately, any virtue in this film's produ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>In a word, it is embarrassing.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>Exceptionally bad!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>All in all its an insult to one's intelligence...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>748 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Sentiment\n",
       "0    A very, very, very slow-moving, aimless movie ...          0\n",
       "1    Not sure who was more lost - the flat characte...          0\n",
       "2    Attempting artiness with black & white and cle...          0\n",
       "3         Very little music or anything to speak of.            0\n",
       "4    The best scene in the movie was when Gerardo i...          1\n",
       "..                                                 ...        ...\n",
       "743  I just got bored watching Jessice Lange take h...          0\n",
       "744  Unfortunately, any virtue in this film's produ...          0\n",
       "745                   In a word, it is embarrassing.            0\n",
       "746                               Exceptionally bad!            0\n",
       "747  All in all its an insult to one's intelligence...          0\n",
       "\n",
       "[748 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_table('imdb_labelled.txt',\n",
    "                  delimiter='\\t',\n",
    "                  header=None,\n",
    "                  names=['Review', 'Sentiment'])\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Sentiment\n",
       "0  A very, very, very slow-moving, aimless movie ...          0\n",
       "1  Not sure who was more lost - the flat characte...          0\n",
       "2  Attempting artiness with black & white and cle...          0\n",
       "3       Very little music or anything to speak of.            0\n",
       "4  The best scene in the movie was when Gerardo i...          1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce ligne de code permet de compter le nombre des commentaires évalués positifs et le nombre des commentaires évalués négatifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    386\n",
       "0    362\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Length'] = train_data['Review'].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant voir l'histogramme de la longueur de la phrase via :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data['Length'].plot(kind = 'hist' , bins = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, vous tracez l'histogramme de la longueur de la phrase via chaque sentiment en :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'Length via each Sentiment')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = train_data.hist(column = 'Length', by = 'Sentiment', bins = 50 , figsize = (14,7));\n",
    "pl.suptitle('Length via each Sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La tokenisation est un moyen de diviser les chaînes en une liste de mots. Dans cet exemple, nous utiliserons le Natural Language Toolkit qui a des fonctions intégrées pour la tokenisation. Il existe 2 types de tokenisation. Le premier type nous permet de convertir la phrase entière en une liste, et l'autre type est l'endroit où nous pouvons convertir des mots séparés en jetons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_tokenize(text):\n",
    "    \"\"\"\n",
    "    take string input and return a list of sentences.\n",
    "    use nltk.sent_tokenize() to split the sentences.\n",
    "    \"\"\"\n",
    "    return nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokenize(text):\n",
    "        \"\"\"\n",
    "        :param text:\n",
    "        :return: list of words\n",
    "        \"\"\"\n",
    "        return nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on teste la fonction sentence_tokenize() :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [A very, very, very slow-moving, aimless movie...\n",
       "1      [Not sure who was more lost - the flat charact...\n",
       "2      [Attempting artiness with black & white and cl...\n",
       "3           [Very little music or anything to speak of.]\n",
       "4      [The best scene in the movie was when Gerardo ...\n",
       "                             ...                        \n",
       "743    [I just got bored watching Jessice Lange take ...\n",
       "744    [Unfortunately, any virtue in this film's prod...\n",
       "745                     [In a word, it is embarrassing.]\n",
       "746                                 [Exceptionally bad!]\n",
       "747    [All in all its an insult to one's intelligenc...\n",
       "Name: Review, Length: 748, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Review'].apply(sentence_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on teste la fonction word_tokenize() :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [A, very, ,, very, ,, very, slow-moving, ,, ai...\n",
       "1      [Not, sure, who, was, more, lost, -, the, flat...\n",
       "2      [Attempting, artiness, with, black, &, white, ...\n",
       "3      [Very, little, music, or, anything, to, speak,...\n",
       "4      [The, best, scene, in, the, movie, was, when, ...\n",
       "                             ...                        \n",
       "743    [I, just, got, bored, watching, Jessice, Lange...\n",
       "744    [Unfortunately, ,, any, virtue, in, this, film...\n",
       "745            [In, a, word, ,, it, is, embarrassing, .]\n",
       "746                              [Exceptionally, bad, !]\n",
       "747    [All, in, all, its, an, insult, to, one, 's, i...\n",
       "Name: Review, Length: 748, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Review'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, l'étape suivante consiste à nous assurer que chaque lettre est en minuscules afin que le modèle fonctionne de manière équivalente :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lower(text):\n",
    "        \"\"\"\n",
    "        :param text:\n",
    "        :return:\n",
    "            Converted text to lower case as in, converting \"Hello\" to \"hello\" or \"HELLO\" to \"hello\".\n",
    "        \"\"\"\n",
    "        return text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testons la fonction to_lower() :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      a very, very, very slow-moving, aimless movie ...\n",
       "1      not sure who was more lost - the flat characte...\n",
       "2      attempting artiness with black & white and cle...\n",
       "3           very little music or anything to speak of.  \n",
       "4      the best scene in the movie was when gerardo i...\n",
       "                             ...                        \n",
       "743    i just got bored watching jessice lange take h...\n",
       "744    unfortunately, any virtue in this film's produ...\n",
       "745                     in a word, it is embarrassing.  \n",
       "746                                 exceptionally bad!  \n",
       "747    all in all its an insult to one's intelligence...\n",
       "Name: Review, Length: 748, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Review'].apply(to_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La prochaine chose que nous devons faire est de supprimer les numéros. La principale raison de la suppression des nombres est que les nombres ne contiennent généralement pas beaucoup d'informations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(text):\n",
    "        \"\"\"\n",
    "        take string input and return a clean text without numbers.\n",
    "        Use regex to discard the numbers.\n",
    "        \"\"\"\n",
    "        output = ''.join(c for c in text if not c.isdigit())\n",
    "        return output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maintenant on teste si la fonction remove_numbers() marche très bien :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     a\n",
       "1    be\n",
       "2     a\n",
       "dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = pd.Series(['a1', 'b2e', 'a3'])\n",
    "z.apply(remove_numbers) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une autre chose importante est de supprimer la ponctuation, car elle n'a souvent aucun sens pour l'analyse des sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "  \n",
    "        return ''.join(c for c in text if c not in punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La prochaine étape du nettoyage de l'ensemble de données consiste à supprimer les mots vides. Les mots vides sont ces mots non pertinents, qui n'ont pas beaucoup de sens et n'aident pas beaucoup dans l'analyse des sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(sentence):\n",
    "        \"\"\"\n",
    "        removes all the stop words like \"is,the,a, etc.\"\n",
    "        \"\"\"\n",
    "        stop_words = stopwords.words('english')\n",
    "        return ' '.join([w for w in nltk.word_tokenize(sentence) if not w in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testons la fonction remove_stopwords :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9     Loved the casting of Jimmy Buffet as the scien...\n",
      "10                 And those baby owls were adorable.  \n",
      "Name: Review, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9     Loved casting Jimmy Buffet science teacher .\n",
       "10                        And baby owls adorable .\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data['Review'][9:11])\n",
    "train_data['Review'][9:11].apply(remove_stopwords) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Le nettoyage des données :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction preprocess() qui contient toutes les fontions qu'on a définit en haut est la suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "        lower_text = to_lower(text)\n",
    "        sentence_tokens = sentence_tokenize(lower_text)\n",
    "        word_list = []\n",
    "        for each_sent in sentence_tokens:\n",
    "            clean_text = remove_numbers(each_sent)\n",
    "            clean_text1 = remove_punct(clean_text)\n",
    "            clean_text2 = remove_stopwords(clean_text1)\n",
    "            word_tokens = word_tokenize(clean_text2)\n",
    "            for i in word_tokens:\n",
    "                word_list.append(i)\n",
    "        return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    A very, very, very slow-moving, aimless movie ...\n",
      "1    Not sure who was more lost - the flat characte...\n",
      "2    Attempting artiness with black & white and cle...\n",
      "3         Very little music or anything to speak of.  \n",
      "4    The best scene in the movie was when Gerardo i...\n",
      "Name: Review, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [slowmoving, aimless, movie, distressed, drift...\n",
       "1    [sure, lost, flat, characters, audience, nearl...\n",
       "2    [attempting, artiness, black, white, clever, c...\n",
       "3                     [little, music, anything, speak]\n",
       "4    [best, scene, movie, gerardo, trying, find, so...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = train_data['Review'].head(5)\n",
    "print(sample_data)\n",
    "sample_data.apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Séparation des données :\n",
    "\n",
    "Notre but est séparer les données et de stocker ceux qui sont positifs dans un tableau des positifs tokens, et ceux qui sont négatifs dans un tableau des négatifs tokens :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "revs = train_data['Review'].copy() #liste des phrases\n",
    "senti= train_data['Sentiment'].copy() #liste des sentiments\n",
    "\n",
    "i=0\n",
    "positiveTokens= [] # tokens du review  positif\n",
    "negativeTokens= [] # tokens du review  negatif\n",
    "\n",
    "\n",
    "#separerles  positifs et negatifs tokens\n",
    "for rev in revs:    \n",
    "    if senti[i]==0:\n",
    "        negativeTokens.append(preprocess(rev)) #tableau de negatif tokens\n",
    "    else:\n",
    "        positiveTokens.append(preprocess(rev)) #tableau de positif tokens\n",
    "    i+=1\n",
    "\n",
    "positiveTokens=(np.concatenate((positiveTokens), axis=0)) #  list de tout les positifs tokens\n",
    "negativeTokens=(np.concatenate((negativeTokens), axis=0)) # list de tout les negatifs tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre objectif ici est de calculer la fréquence d'un mot pour bien déterminer est-ce qu'il est positif ou négatif :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>positive Freq</th>\n",
       "      <th>negative Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meaning</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>artless</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jealousy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bakery</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  positive Freq  negative Freq\n",
       "0   meaning              1              2\n",
       "1   artless              0              1\n",
       "2       rpg              0              1\n",
       "3  jealousy              1              0\n",
       "4    bakery              0              1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordFreq=[]\n",
    "\n",
    "#calculater frequence d'un mot (Number of occurences of a word in Tokens)\n",
    "def wordFrequency(word,array): \n",
    "    wordFreq=np.count_nonzero(array==word)\n",
    "    return wordFreq\n",
    "\n",
    "#--------------------- VISUALISATION-------------------------\n",
    "#create dataframe of [word,posFreq,negFreq]\n",
    "for word in list(set(np.concatenate((positiveTokens,negativeTokens), axis=0))):\n",
    "    WordFreq.append([word,wordFrequency(word,positiveTokens),wordFrequency(word,negativeTokens)]) #[word,posFreq,negFreq]\n",
    "wordFreqDF = pd.DataFrame(WordFreq, columns=['word','positive Freq', 'negative Freq'])\n",
    "wordFreqDF.head()\n",
    "#---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4- Covertir les lignes en vecteurs [PosF, NegF] :\n",
    "\n",
    "Le but ici est de convertir nos lignes ou nos commentaires sous forme des vecteurs qui précisent par la suite si ces commentaires sont positifs ou négatifs à partier de la comparaison entre la fréquence des mots positifs et négatifs dans ce commentaire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>PosF</th>\n",
       "      <th>NegF</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>94</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>25</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>140</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>123</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Worst hour and a half of my life!Oh my gosh!</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>I had to walk out of the theatre for a few min...</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>I hate movies like that.</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Yeah, the movie pretty much sucked.</td>\n",
       "      <td>95</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>THERE IS NO PLOT OR STORYLINE!!</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review  PosF  NegF  sentiment\n",
       "0   A very, very, very slow-moving, aimless movie ...    94   104          0\n",
       "1   Not sure who was more lost - the flat characte...    25    34          0\n",
       "2   Attempting artiness with black & white and cle...   140   214          0\n",
       "3        Very little music or anything to speak of.      16    24          0\n",
       "4   The best scene in the movie was when Gerardo i...   123   118          1\n",
       "..                                                ...   ...   ...        ...\n",
       "95     Worst hour and a half of my life!Oh my gosh!       3    21          0\n",
       "96  I had to walk out of the theatre for a few min...     7    18          0\n",
       "97                         I hate movies like that.      40    39          0\n",
       "98              Yeah, the movie pretty much sucked.      95   123          0\n",
       "99                  THERE IS NO PLOT OR STORYLINE!!       5    26          0\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataSet=[]\n",
    "  \n",
    "#calculate row of dataset [review,PosF,NegF,sentiment]\n",
    "def phraseFreq(phrase,sentiment):  \n",
    "    Posfreq=0\n",
    "    Negfreq=0\n",
    "    for word in preprocess(phrase):\n",
    "        Posfreq+=wordFrequency(word,positiveTokens) #la somme des frequences positifs\n",
    "        Negfreq+=wordFrequency(word,negativeTokens) #la somme des frequences negatifs\n",
    "\n",
    "    return [phrase,Posfreq,Negfreq,sentiment]\n",
    "\n",
    "\n",
    "#convert review(input) to vector(PosF,NegF)\n",
    "def review2vec(review):\n",
    "    Posfreq=0\n",
    "    Negfreq=0\n",
    "    for word in preprocess(phrase):\n",
    "        Posfreq+=wordFrequency(word,positiveTokens)\n",
    "        Negfreq+=wordFrequency(word,negativeTokens)\n",
    "    return [Posfreq,Negfreq]\n",
    "\n",
    "\n",
    "def createDataSet():\n",
    "    i=0\n",
    "    for rev in revs:\n",
    "        DataSet.append(phraseFreq(rev,senti[i]))\n",
    "        i+=1\n",
    "\n",
    "createDataSet()\n",
    "\n",
    "DataSet=pd.DataFrame(DataSet, columns=['review','PosF', 'NegF','sentiment'])\n",
    "DataSet.head(100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 94. 104.] 0\n"
     ]
    }
   ],
   "source": [
    "# Données + classes cibles\n",
    "data   = np.array(DataSet.values[:,1:3], dtype=np.float32)\n",
    "target = DataSet.values[:,-1]\n",
    "print(data[0],target[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5- Division des données :\n",
    "\n",
    "La division des données en données d'entrainement et données de test, les données de test représentent 10 des données dans notre cas :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Partition aléatoire de l’échantillon\n",
    "# 10%=100 exemples pour le test\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, target, test_size=0.1)\n",
    "\n",
    "len(testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La transformation des étiquettes ou des sentiments en des vecteurs binaires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       ...,\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformer l'étiquette(sentiments) en un vecteur binaire : 3 --> (0,0,0,1,0,0,0,0,0,0)\n",
    "trainYC = np.array(list(map(lambda x: [1,0] if x == 1 else [0,1], trainY)))\n",
    "testYC = np.array(list(map(lambda x: [1,0] if x == 1 else [0,1], testY)))\n",
    "\n",
    "\n",
    "trainYC\n",
    "\n",
    "# review => network => [0.82,0.18]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6- Les réseaux neurones multicouches (PMC) :\n",
    "\n",
    "Là notre classe principale qui implémente l'algorithme des réseaux neurones multicouches et qui définit plusieurs méthodes, parmi eux : __init__() : fonction d'initialisation, sigmoid() et dsigmoid() qui concerne la fonction d'activation d'un neurone, forward_pass() pour le Calcul et la mémorisation de l'état de tous les neurones du réseau, predict pour le calcul de la sortie du réseau associée à une entrée X (les états des autres neurones ne sont pas mémorisés), quadratic_loss() pour le calcul de l'erreur quadratique moyenne, compute_gradient() pour le Calcul des gradients locaux, update_with_bloc() pour la Mise à jour par rapport à l'erreur moyenne (relative à un bloc d'exemples), et fit() pour l'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron:\n",
    "    \n",
    "    def __init__(self, arch , alpha = 0.1):\n",
    "        # poids + biais\n",
    "        self.W = {}\n",
    "        self.B = {}\n",
    "        \n",
    "        # Taux d'adaptation\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # Architecture :nbre de couches et nombre de neurones par couche\n",
    "        self.arch = arch\n",
    "        \n",
    "        # Initialisation des poids: valeurs issues d'une distribution normale\n",
    "        for i in np.arange(1,len(self.arch)):  \n",
    "            # Poids\n",
    "            w = np.random.randn(self.arch[i], self.arch[i-1])\n",
    "            self.W[i] = w/np.sqrt(self.arch[i])\n",
    "            # Bias\n",
    "            b = np.random.randn(self.arch[i],1)\n",
    "            self.B[i] = b/np.sqrt(self.arch[i])            \n",
    "            \n",
    "            \n",
    "    def sigmoid(self, x):\n",
    "        return 1.0/(1 + np.exp(-x))\n",
    "    \n",
    "    \n",
    "    def dsigmoid(self, x): # x correspond ici à sigmoid(uj(t)), voir le cours\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    \n",
    "    #Calcul et mémorisation de l'état de tous les neurones du réseau \n",
    "    def forward_pass(self, x):\n",
    "        a = np.atleast_2d(x).T\n",
    "        \n",
    "        stats = {}\n",
    "        stats[0] = a\n",
    "        for layer in np.arange(1, len(self.arch)):\n",
    "            a = self.sigmoid(np.dot(self.W[layer], a) + self.B[layer])\n",
    "            stats[layer] = a\n",
    "        return stats    \n",
    "    \n",
    "    \n",
    "    #Sortie du réseau associée à une entrée X (les états des autres neurones ne sont pas mémorisés)\n",
    "    def predict(self, X):\n",
    "        a = np.atleast_2d(X).T\n",
    "        for layer in np.arange(1, len(self.arch)):\n",
    "            a = self.sigmoid(np.dot(self.W[layer], a) + self.B[layer])\n",
    "        return a\n",
    "    \n",
    "    \n",
    "    #Calcul de l'erreur quadratique moyenne\n",
    "    def quadratic_loss(self, X, Y):\n",
    "        Y = np.atleast_2d(Y).T\n",
    "        predictions = self.predict(X)\n",
    "        n = X.shape[0]\n",
    "        loss = (1/n) * 0.5 * np.sum((predictions - Y) ** 2) \n",
    "        return loss \n",
    "    \n",
    "    \n",
    "    #Calcul des gradients locaux \n",
    "    def compute_gradient(self, x, y):\n",
    "     \n",
    "        L = len(self.arch) - 1 # indice de la couche de sortie \n",
    "        # Gradients\n",
    "        Gw = {}\n",
    "        Gb = {}\n",
    "        A = self.forward_pass(x)\n",
    "        # Les vecteurs delta  \n",
    "        D = {}\n",
    "        y = np.atleast_2d(y).T\n",
    "        deltaL = (A[L] - y) * self.dsigmoid(A[L])\n",
    "        D[L] = deltaL # Pour la sortie \n",
    "        \n",
    "        # Calculer les vecteurs delta des autres couches en utilisants les vecteurs delta de la couche suivante\n",
    "        for l in np.arange(L-1, 0, -1):\n",
    "            D[l] = (self.W[l+1].T.dot(D[l+1])) * self.dsigmoid(A[l])\n",
    "        \n",
    "        for l in np.arange(L, 0, -1):\n",
    "            Gb[l] = D[l]\n",
    "            Gw[l] = D[l].dot(A[l-1].T)        \n",
    "       \n",
    "        return (Gw, Gb)\n",
    "    \n",
    "    \n",
    "    # Mise à jour par rapport à l'erreur moyenne (relative à un bloc d'exemples)\n",
    "    def update_with_bloc(self, bloc):\n",
    "      \n",
    "        m = len(bloc)\n",
    "        # Gradients locaux\n",
    "        GCw = {}\n",
    "        GCb = {}\n",
    "        # Initialiser à zeros \n",
    "        for i in np.arange(1,len(self.arch)):\n",
    "            GCw[i] = np.zeros(self.W[i].shape)\n",
    "            GCb[i] = np.zeros(self.B[i].shape)\n",
    "            \n",
    "        # Calcul des gradients\n",
    "        for x, y in bloc:\n",
    "            Gw, Gb = self.compute_gradient(x, y)\n",
    "            for i in np.arange(1,len(self.arch)): \n",
    "                GCw[i] += Gw[i]\n",
    "                GCb[i] += Gb[i]\n",
    "                \n",
    "        # Mettre à jour les poids \n",
    "        for l in np.arange(1,len(self.arch)):\n",
    "            self.W[l] = self.W[l] - (self.alpha/m)*(GCw[l])\n",
    "            self.B[l] = self.B[l] - (self.alpha/m)*(GCb[l])\n",
    "    \n",
    "    \n",
    "    # Iteration: entrainement en utilisant tous les exemples, un bloc de taille bloc_size chaque fois\n",
    "    def train(self, D, bloc_size):\n",
    "        train_size = len(D)\n",
    "        np.random.shuffle(D) # tirage au sort\n",
    "        \n",
    "        # Bloc d'exemples\n",
    "        blocs = [D[k : k + bloc_size] for k in range(0, train_size, bloc_size)]\n",
    "        \n",
    "        for bloc in blocs: # Mise à jour suite au passage de chaque bloc\n",
    "            self.update_with_bloc(bloc)\n",
    "  \n",
    "\n",
    "    # Apprentissage\n",
    "    def fit(self, X, Y, bloc_size = 20, iterations = 10000, error_min = 0.001, displayPeriod = 5000):\n",
    "     \n",
    "        # Exemples avec X et Y Assemblés\n",
    "        D = list(zip(X,Y))\n",
    "        \n",
    "        # Erreurs\n",
    "        errors = [self.quadratic_loss(X,Y)]   # Erreur initiale    \n",
    "        \n",
    "        iter = 0\n",
    "        print(\"Itération: {}-{}, Erreur: {:.6f}\".format(iter, iterations,errors[iter]))\n",
    "        while iter < iterations and errors[iter] > error_min: # Tour de boucle \n",
    "            \n",
    "            self.train(D, bloc_size)  # Mettre à jour \n",
    "            errors.append(self.quadratic_loss(X,Y))         # Nouvelle erreur\n",
    "          \n",
    "            if (iter+1) % displayPeriod == 0:\n",
    "                print(\"Itération: {}-{}, Error: {:.6f}\".format(iter + 1, iterations,errors[iter]))\n",
    "            iter += 1\n",
    "        \n",
    "        if errors[iter] < error_min: # Erreur inférieur à la valeur minimale\n",
    "            print(\"Fin: erreur minimale atteinte : {:.6f}.\", errors[iter])\n",
    "        elif iter == iterations:\n",
    "            print(\"Fin: nombre maximum d'itérations atteint.\")\n",
    "       \n",
    "        return (errors, iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on entraine notre modèle à travers l'initialisation et l'apprentissage :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nessm\\AppData\\Local\\Temp/ipykernel_13800/1717125781.py:25: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0/(1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itération: 0-500, Erreur: 0.301148\n",
      "Itération: 20-500, Error: 0.114453\n",
      "Itération: 40-500, Error: 0.127220\n",
      "Itération: 60-500, Error: 0.126362\n",
      "Itération: 80-500, Error: 0.119776\n",
      "Itération: 100-500, Error: 0.104387\n",
      "Itération: 120-500, Error: 0.117441\n",
      "Itération: 140-500, Error: 0.125834\n",
      "Itération: 160-500, Error: 0.098903\n",
      "Itération: 180-500, Error: 0.115985\n",
      "Itération: 200-500, Error: 0.105444\n",
      "Itération: 220-500, Error: 0.102406\n",
      "Itération: 240-500, Error: 0.109162\n",
      "Itération: 260-500, Error: 0.104526\n",
      "Itération: 280-500, Error: 0.113659\n",
      "Itération: 300-500, Error: 0.109934\n",
      "Itération: 320-500, Error: 0.109928\n",
      "Itération: 340-500, Error: 0.105818\n",
      "Itération: 360-500, Error: 0.108382\n",
      "Itération: 380-500, Error: 0.112309\n",
      "Itération: 400-500, Error: 0.110223\n",
      "Itération: 420-500, Error: 0.102715\n",
      "Itération: 440-500, Error: 0.101255\n",
      "Itération: 460-500, Error: 0.118401\n",
      "Itération: 480-500, Error: 0.110003\n",
      "Itération: 500-500, Error: 0.100959\n",
      "Fin: nombre maximum d'itérations atteint.\n"
     ]
    }
   ],
   "source": [
    "# Initialisation et apprentissage\n",
    "# trainX.shape[1]\n",
    "# testY\n",
    "pmc = MultiLayerPerceptron(arch=[trainX.shape[1],15,15,2], alpha=0.1)\n",
    "(errs, iter_fin) = pmc.fit(trainX, trainYC, iterations=500, bloc_size=5, error_min=0.00001, displayPeriod=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on teste notre modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95. 75.]\n",
      "1\n",
      "Sortie prédite : \n",
      "[[0.91744561]\n",
      " [0.09266412]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nessm\\AppData\\Local\\Temp/ipykernel_13800/1717125781.py:25: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0/(1 + np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "# Test pour un exemple \n",
    "# data.shape[0]\n",
    "randIndex = np.random.randint(0,data.shape[0]-1,1)[0]\n",
    "# print('Exemple : '+str(randIndex)+', classe réelle : '+str(target[randIndex]))\n",
    "print(testX[7])\n",
    "print(testY[7])\n",
    "# # print(data[randIndex])\n",
    "print('Sortie prédite : \\n'+str(pmc.predict(testX[7]))+')' )\n",
    "# testY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On effectue une comparaison entre la sortie calculée et la sortie réelle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0', '0', '1', '0', '1', '0', '1', '1', '0', '0', '0', '1', '1', '0', '0', '0', '1', '0', '0', '0', '1', '1', '0', '0', '0', '0', '0', '1', '0', '1', '1', '1', '1', '0', '1', '0', '0', '1', '1', '0', '0', '1', '1', '0', '1', '0', '0', '1', '1', '0', '1', '0', '0', '1', '1', '0', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '0', '0', '1', '1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nessm\\AppData\\Local\\Temp/ipykernel_13800/1717125781.py:25: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0/(1 + np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "targetTestR = ['']*(np.array(testY).shape[0])\n",
    "\n",
    "# targetTestR\n",
    "for index in range(testX.shape[0]):     \n",
    "    o = np.round(pmc.predict(testX[index]),0)[:,0].astype(int)\n",
    "    if((o==np.array([1,0])).all()):\n",
    "        targetTestR[index] = 1\n",
    "    elif((o==np.array([0,1])).all()):\n",
    "        targetTestR[index] = 0\n",
    "\n",
    "        \n",
    "# Sortie calculée et sortie réelle pour la base de test      \n",
    "targetTestRF=list(map(lambda x: '1' if x == 1 else '0', targetTestR))\n",
    "# print(targetTestR)\n",
    "testYF=list(map(lambda x: '1' if x == 1 else '0', testY))\n",
    "print(testYF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et pour terminer notre travail, on mesure la performance à travers le calcul du taux de classification correcte :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8933333333333333"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taux de la classification correcte \n",
    "metrics.accuracy_score(testYF, targetTestRF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
